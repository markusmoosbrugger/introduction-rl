{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RL Grid Navigation\n",
    "\n",
    "The goal of this assignment is to train an agent to navigate efficiently within a grid.\n",
    "This means the agent should avoid the fields where bombs are placed and find the shortest path\n",
    "from its starting position to the end position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.core.display import display\n",
    "\n",
    "from grid_env import GridEnv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(4)\n",
      "Observation space: Tuple(Discrete(8), Discrete(8))\n",
      "Reward range: (-100, 100)\n"
     ]
    }
   ],
   "source": [
    "env = GridEnv()\n",
    "\n",
    "# Show action space, observation space and reward range\n",
    "print(f'Action space: {env.action_space}')\n",
    "print(f'Observation space: {env.observation_space}')\n",
    "print(f'Reward range: {env.reward_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting position: (0, 0)\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "|\t.\t.\t!!\t.\t.\t.\t.\tB\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t!!\t|\n",
      "|\t.\t!!\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\txA\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "Sample action: 0\n",
      "Sample observation: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "# Reset environment and print starting position\n",
    "print(f'Starting position: {env.reset()}')\n",
    "\n",
    "# Render the environment\n",
    "env.render()\n",
    "\n",
    "# Sample a random action and a random observation\n",
    "print(f'Sample action: {env.action_space.sample()}')\n",
    "print(f'Sample observation: {env.observation_space.sample()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: left, observation: (0, 0), reward: -1, done: False.\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "|\t.\t.\t!!\t.\t.\t.\t.\tB\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t!!\t|\n",
      "|\t.\t!!\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\txA\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "Action: right, observation: (1, 0), reward: -1, done: False.\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "|\t.\t.\t!!\t.\t.\t.\t.\tB\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t!!\t|\n",
      "|\t.\t!!\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\tA\tx\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "Action: right, observation: (2, 0), reward: -1, done: False.\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n",
      "|\t.\t.\t!!\t.\t.\t.\t.\tB\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t.\t|\n",
      "|\t.\t.\t.\t.\t.\t.\t.\t!!\t|\n",
      "|\t.\t!!\t.\t.\t.\t.\t!!\t.\t|\n",
      "|\tA\t.\tx\t.\t.\t.\t.\t.\t|\n",
      "|\t___\t___\t___\t___\t___\t___\t___\t___\t|\n"
     ]
    }
   ],
   "source": [
    "# Perform a few steps with random actions\n",
    "env.reset()\n",
    "num_steps = 3\n",
    "for step in range(num_steps):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "\n",
    "    print(f'Action: {env.get_action_name(action)}, observation: {observation}, reward: {reward}, done: {done}.')\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(env):\n",
    "    # Q table is dict of dict\n",
    "    Q = {}\n",
    "    for i in range(env.width):\n",
    "        for j in range(env.height):\n",
    "            Q[(i, j)] = {}\n",
    "            for a in env.action_names:\n",
    "                Q[(i, j)][a] = 0\n",
    "    return Q\n",
    "\n",
    "def get_action(env, model, state, epsilon):\n",
    "    random_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "    # exploit\n",
    "    if random_tradeoff > epsilon:\n",
    "        action_dict = model.get(state)\n",
    "        action_name = max(action_dict, key=action_dict.get)\n",
    "\n",
    "        # get index number of action\n",
    "        return env.get_action_index(action_name)\n",
    "\n",
    "    # explore\n",
    "    else:\n",
    "        return env.action_space.sample()\n",
    "\n",
    "def update_model_sarsa(env, model, state, next_state, reward, action, next_action, alpha, gamma):\n",
    "    pass\n",
    "\n",
    "def update_model_qlearning(env, model, state, next_state, reward, action, alpha, gamma):\n",
    "    pass\n",
    "\n",
    "def get_epsilon(episode, min_epsilon=0.01, max_epsilon=1, decay=0.01):\n",
    "    return min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SARSA\n",
    "\n",
    "### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_sarsa(env, episodes=1000):\n",
    "\n",
    "\n",
    "    # variables\n",
    "    total_timesteps = 0\n",
    "    scores = []\n",
    "    gamma = 0.7     # discount factor\n",
    "    alpha = 0.5     # learning rate\n",
    "\n",
    "    model = get_model(env)\n",
    "\n",
    "    # TODO: remove this return statement\n",
    "    return model, scores\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        # start episode and get initial observation\n",
    "        state = env.reset()\n",
    "        epsilon = get_epsilon(episode)\n",
    "\n",
    "        # reset score and epochs\n",
    "        score = 0\n",
    "        epochs = 0\n",
    "\n",
    "        # get first action\n",
    "        action = get_action(env, model, state, epsilon)\n",
    "\n",
    "        done = False\n",
    "\n",
    "        # loop through steps\n",
    "        while not done:\n",
    "            # TODO implement SARSA\n",
    "\n",
    "\n",
    "            # update score\n",
    "            score += reward\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "\n",
    "        print(f'Episode {episode} finished, Score: {score}, Epochs: {epochs}, '\n",
    "                  f'Epsilon: {epsilon:.2f}')\n",
    "\n",
    "        total_timesteps += epochs\n",
    "        scores.append(score)\n",
    "\n",
    "    # close the environment\n",
    "    env.close()\n",
    "\n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = GridEnv()\n",
    "episodes = 500\n",
    "model, scores = train_sarsa(env, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       0                       1     ...  6     7                     \n       0  1  2  3  4  5  6  7  0  1  ...  6  7  0  1  2  3  4  5  6  7\ndown   0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nright  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nup     0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nleft   0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n\n[4 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">0</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">6</th>\n      <th colspan=\"8\" halign=\"left\">7</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>...</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>down</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>right</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>up</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>left</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 64 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_training_development(episodes, scores):\n",
    "    x = range(episodes)\n",
    "    plt.plot(x, scores)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Training scores\")\n",
    "    plt.title(\"Score development over all episodes\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize Q-Table\n",
    "df = pd.DataFrame(model)\n",
    "display(df)\n",
    "\n",
    "# Visualize training development\n",
    "#visualize_training_development(episodes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_agent(env, model):\n",
    "    # TODO remove this return statement\n",
    "    return 0\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    num_steps = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = get_action(env, model, state, 0)\n",
    "        print(f'Action: {env.get_action_name(action)}')\n",
    "        state, reward, done, info = env.step(action)\n",
    "        num_steps += 1\n",
    "\n",
    "    print(f'Finished in {num_steps} steps.')\n",
    "    env.render()\n",
    "    return num_steps\n",
    "\n",
    "\n",
    "def evaluate_agent(env, num_steps_agent):\n",
    "    num_steps_optimum = env.get_minimum_number_of_steps()\n",
    "    print(f'Minimum number steps required: {num_steps_optimum}')\n",
    "    print(f'Number steps test agent: {num_steps_agent}')\n",
    "\n",
    "    if num_steps_agent == num_steps_optimum:\n",
    "        print(f'SUCCESS! Optimal strategy found by agent.')\n",
    "    else:\n",
    "        print(f'FAILURE! Suboptimal strategy found by agent. '\n",
    "              f'Difference to optimal strategy: {num_steps_agent - num_steps_optimum} steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number steps required: 14\n",
      "Number steps test agent: 0\n",
      "FAILURE! Suboptimal strategy found by agent. Difference to optimal strategy: -14 steps.\n"
     ]
    }
   ],
   "source": [
    "num_steps = test_agent(env, model)\n",
    "evaluate_agent(env, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Q-Learning\n",
    "\n",
    "### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_qlearning(env, episodes=1000):\n",
    "\n",
    "    # variables\n",
    "    total_timesteps = 0\n",
    "    scores = []\n",
    "    gamma = 0.7\n",
    "    alpha = 0.5\n",
    "\n",
    "    model = get_model(env)\n",
    "\n",
    "    # TODO: remove this return statement\n",
    "    return model, scores\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        # start episode and get initial observation\n",
    "        state = env.reset()\n",
    "        epsilon = get_epsilon(episode)\n",
    "\n",
    "        # reset score and epochs\n",
    "        score = 0\n",
    "        epochs = 0\n",
    "\n",
    "        done = False\n",
    "\n",
    "        # loop through steps\n",
    "        while not done:\n",
    "            # TODO: implement Q-learning\n",
    "\n",
    "            # update score\n",
    "            score += reward\n",
    "\n",
    "            # update epoch\n",
    "            epochs += 1\n",
    "\n",
    "\n",
    "        print(f'Episode {episode} finished, Score: {score}, Epochs: {epochs}, '\n",
    "                  f'Epsilon: {epsilon:.2f}')\n",
    "\n",
    "        total_timesteps += epochs\n",
    "        scores.append(score)\n",
    "\n",
    "    # close the environment\n",
    "    env.close()\n",
    "\n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = GridEnv()\n",
    "episodes = 500\n",
    "model, scores = train_qlearning(env, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       0                       1     ...  6     7                     \n       0  1  2  3  4  5  6  7  0  1  ...  6  7  0  1  2  3  4  5  6  7\ndown   0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nright  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nup     0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\nleft   0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n\n[4 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">0</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">6</th>\n      <th colspan=\"8\" halign=\"left\">7</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>...</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>down</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>right</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>up</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>left</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 64 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(model)\n",
    "display(df)\n",
    "\n",
    "#visualize_training_development(episodes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number steps required: 14\n",
      "Number steps test agent: 0\n",
      "FAILURE! Suboptimal strategy found by agent. Difference to optimal strategy: -14 steps.\n"
     ]
    }
   ],
   "source": [
    "num_steps_agent = test_agent(env, model)\n",
    "evaluate_agent(env, num_steps_agent)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (introduction-rl)",
   "language": "python",
   "name": "pycharm-a21a4d24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}